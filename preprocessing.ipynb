{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests is already installed.\n",
      "pandas is already installed.\n",
      "numpy is already installed.\n",
      "altair is already installed.\n",
      "vega_datasets is already installed.\n",
      "scikit-learn not found. Installing...\n",
      "seaborn is already installed.\n",
      "matplotlib is already installed.\n",
      "statsmodels is already installed.\n",
      "scipy is already installed.\n",
      "Standard library os is available.\n",
      "Standard library zipfile is available.\n",
      "Standard library urllib is available.\n",
      "Standard library csv is available.\n",
      "Standard library math is available.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.stats import t\n",
    "from urllib.request import urlretrieve\n",
    "# import requests\n",
    "import subprocess\n",
    "# import sys\n",
    "# import os\n",
    "# from urllib.request import urlretrieve\n",
    "# from zipfile import ZipFile\n",
    "# Function to install missing packages\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Read the requirements.txt file and store libraries with their versions\n",
    "libraries = {}\n",
    "\n",
    "with open('requirements.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        # Each line in the file is in the form 'library==version'\n",
    "        if '==' in line:\n",
    "            lib, version = line.strip().split('==')\n",
    "            libraries[lib] = version\n",
    "\n",
    "# Standard libraries that do not require installation\n",
    "standard_libraries = [\n",
    "    'os', 'zipfile', 'urllib', 'csv', 'math'\n",
    "]\n",
    "\n",
    "# Check third-party libraries and install them if missing\n",
    "for lib, version in libraries.items():\n",
    "    try:\n",
    "        __import__(lib)\n",
    "        print(f\"{lib} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"{lib} not found. Installing...\")\n",
    "        install_package(f\"{lib}=={version}\")\n",
    "\n",
    "# Confirm standard libraries are available (they should be, as they are part of Python)\n",
    "for lib in standard_libraries:\n",
    "    try:\n",
    "        __import__(lib)\n",
    "        print(f\"Standard library {lib} is available.\")\n",
    "    except ImportError:\n",
    "        print(f\"Standard library {lib} not found, but it should be included in the Python standard library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_cdc_survey_2021():\n",
    "    \"\"\"\n",
    "    Reads the CDC survey input file.\n",
    "\n",
    "    :return: CDC survey dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    url='https://drive.google.com/file/d/17Khw3R3cTaAizs6CzbtCU8ZmxWSRn_mG/view?usp=share-link'\n",
    "    url='https://drive.usercontent.google.com/download?id={}&export=download&authuser=0&confirm=t'.format(url.split('/')[-2])\n",
    "\n",
    "    #limiting the number of columns we're importing since the 2021 data will only be used for Supervised learning\n",
    "    col_incl = [\"Interview Year\", \"State Abbr.\", \"Age Group\", \"Heart Disease\", \"Asthma\", \"Kidney Disease\", \"Diabetes\", \"BMI Category\"]\n",
    "\n",
    "    column_types = {'Interview Year': \"int16\", 'Heart Disease': bool, 'Asthma': bool, 'Kidney Disease': bool, 'Diabetes': bool}\n",
    "    \n",
    "    df = pd.read_csv(url, usecols=col_incl, dtype = column_types)\n",
    "\n",
    "    return df\n",
    "\n",
    "def import_cdc_survey_2022():\n",
    "    \"\"\"\n",
    "    Reads the CDC survey input file.\n",
    "\n",
    "    :return: CDC survey dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    url='https://drive.google.com/file/d/1g69nPHfxfNtWnKBoq2SODoPzlCClYdhc/view?usp=share-link'\n",
    "    url='https://drive.usercontent.google.com/download?id={}&export=download&authuser=0&confirm=t'.format(url.split('/')[-2])\n",
    "\n",
    "    column_types = {'Interview Year': \"int16\", 'Is Adult Landline': bool, 'Num of Adults Landline': \"float32\",\n",
    "                    'Num of Adults Cell': \"float32\", 'Could Afford Doctor': bool, 'Exercise in Past 30 Days': bool,\n",
    "                    'Heart Attack': bool, 'Heart Disease': bool, 'Stroke': bool, 'Asthma': bool, 'Asthma in Effect': bool,\n",
    "                    'Depression': bool, 'Kidney Disease': bool, 'Arthritis': bool, 'Diabetes': bool, 'Weight in Pounds': \"float32\",\n",
    "                    'Height in Inches': \"float32\", 'Cigarettes per Day': \"float32\", 'Drinks in Last 30 Days': \"float32\", \n",
    "                    'Prediabetes': bool, 'Metropolitan': bool, 'Heavy Alcohol Consumption': bool, 'Hours of Sleeping': \"float32\", 'Shortness of Breath': bool}\n",
    "    \n",
    "    df = pd.read_csv(url, dtype=column_types)\n",
    "\n",
    "    return df\n",
    "\n",
    "def import_covid_dataset():\n",
    "    \"\"\"\n",
    "    Reads the COVID input file.\n",
    "\n",
    "    :return: COVID dataset as a pandas dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    url='https://drive.google.com/file/d/181jSYrgqjUYc-ba94dl2Lw4Z19vV-ha-/view?usp=share_link'\n",
    "    url='https://drive.usercontent.google.com/download?id={}&export=download&authuser=0&confirm=t'.format(url.split('/')[-2])\n",
    "\n",
    "    col_incl = [\"Start Date\", \"End Date\", \"Group\", \"Year\", \"State\", \"Condition Group\", \"Condition\", \"Age Group\", \"COVID-19 Deaths\"]\n",
    "\n",
    "    column_types = {'Year': \"float32\", 'COVID-19 Deaths': \"float32\"}\n",
    "    \n",
    "    df = pd.read_csv(url, usecols = col_incl, dtype=column_types)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def import_mortality():\n",
    "    \"\"\"\n",
    "    Reads the mortality input file and parses the contents using CSV format.\n",
    "\n",
    "    :return: Mortality dataframe.\n",
    "    \"\"\"\n",
    "    # df = pd.read_csv('mortality.csv')\n",
    "    url='https://drive.google.com/file/d/10HPyYhcNzQm4JQp6EpoWrJWEmEO6uVS7/view?usp=share-link'\n",
    "    url='https://drive.usercontent.google.com/download?id={}&export=download&authuser=0&confirm=t'.format(url.split('/')[-2])\n",
    "    df = pd.read_csv(url, index_col = [0])\n",
    "    return df\n",
    "\n",
    "def import_pop_dataset():\n",
    "    \"\"\"\n",
    "    Reads the US Population input file.\n",
    "\n",
    "    :return: US Resident Population dataset as a pandas dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    url='https://drive.google.com/file/d/1DsnRBQ0uczuLMQySqXW91zs8sljoPO2U/view?usp=share-link'\n",
    "    url='https://drive.usercontent.google.com/download?id={}&export=download&authuser=0&confirm=t'.format(url.split('/')[-2])\n",
    "\n",
    "    col_incl = [\"NAME\", \"AGE\", \"POPESTIMATE2021\", \"POPESTIMATE2022\", \"SEX\", \"ORIGIN\"]\n",
    "\n",
    "    column_types = {'AGE': \"int32\", 'POPESTIMATE2021': \"int64\", 'POPESTIMATE2022': \"int64\"}\n",
    "    \n",
    "    df = pd.read_csv(url, usecols = col_incl, dtype=column_types)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean COVID Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_covid_dataset():\n",
    "    \"\"\"\n",
    "    Cleans and aggregates the COVID-19 dataset.\n",
    "\n",
    "    Returns:\n",
    "        df_sup: A cleaned dataframe for use in the supervised portion of the project\n",
    "        df_unsup: A cleaned dataframe for use in the unsupervised portion of the project\n",
    "    \"\"\"\n",
    "    # Dictionary to map state names to abbreviations\n",
    "    state_name_to_abbr = {\n",
    "        'ALABAMA': 'AL', 'ALASKA': 'AK', 'ARIZONA': 'AZ', 'ARKANSAS': 'AR', \n",
    "        'CALIFORNIA': 'CA', 'COLORADO': 'CO', 'CONNECTICUT': 'CT', 'DELAWARE': 'DE', \n",
    "        'DISTRICT OF COLUMBIA': 'DC', 'FLORIDA': 'FL', 'GEORGIA': 'GA', 'HAWAII': 'HI', \n",
    "        'IDAHO': 'ID', 'ILLINOIS': 'IL', 'INDIANA': 'IN', 'IOWA': 'IA', 'KANSAS': 'KS', \n",
    "        'KENTUCKY': 'KY', 'LOUISIANA': 'LA', 'MAINE': 'ME', 'MARYLAND': 'MD', \n",
    "        'MASSACHUSETTS': 'MA', 'MICHIGAN': 'MI', 'MINNESOTA': 'MN', 'MISSISSIPPI': 'MS', \n",
    "        'MISSOURI': 'MO', 'MONTANA': 'MT', 'NEBRASKA': 'NE', 'NEVADA': 'NV', \n",
    "        'NEW HAMPSHIRE': 'NH', 'NEW JERSEY': 'NJ', 'NEW MEXICO': 'NM', 'NEW YORK': 'NY', \n",
    "        'NEW YORK CITY': 'NYC', 'NORTH CAROLINA': 'NC', 'NORTH DAKOTA': 'ND', 'OHIO': 'OH', \n",
    "        'OKLAHOMA': 'OK', 'OREGON': 'OR', 'PENNSYLVANIA': 'PA', 'RHODE ISLAND': 'RI', \n",
    "        'SOUTH CAROLINA': 'SC', 'SOUTH DAKOTA': 'SD', 'TENNESSEE': 'TN', 'TEXAS': 'TX', \n",
    "        'UTAH': 'UT', 'VERMONT': 'VT', 'VIRGINIA': 'VA', 'WASHINGTON': 'WA', \n",
    "        'WEST VIRGINIA': 'WV', 'WISCONSIN': 'WI', 'WYOMING': 'WY', 'PUERTO RICO': 'PR'\n",
    "    }\n",
    "\n",
    "    # Pass in imported COVID dataset\n",
    "    df = import_covid_dataset()\n",
    "    \n",
    "    # Filter out rows where 'state' is missing or irrelevant\n",
    "    df_cleaned = df[df['State'].notna()]\n",
    "    df_cleaned['State'] = df_cleaned['State'].str.upper()\n",
    "    df_cleaned = df_cleaned[df_cleaned['State'] != 'UNITED STATES']\n",
    "\n",
    "    # Map state names to abbreviations\n",
    "    df_cleaned['state_abbr'] = df_cleaned['State'].map(state_name_to_abbr)\n",
    "\n",
    "    # Handle data types and missing data\n",
    "    df_cleaned['Year'] = df_cleaned['Year'].fillna(0).astype(int)\n",
    "    df_cleaned['COVID-19 Deaths'] = df_cleaned['COVID-19 Deaths'].fillna(0).astype(int)\n",
    "\n",
    "    # Drop rows where 'age_group' is 'Not stated' or 'All Ages'\n",
    "    df_cleaned = df_cleaned[~df_cleaned['Age Group'].isin(['Not stated', 'All Ages'])]\n",
    "\n",
    "    # Drop rows where the condition is 'COVID-19' (as we focus on pre-existing conditions)\n",
    "    df_cleaned = df_cleaned[df_cleaned['Condition'] != 'COVID-19']\n",
    "\n",
    "    #Here we will focus on cleaning specifically for the Supervised portion of the project\n",
    "    # We only want to focus on annual data as that is the level of the BRFSS survey data that we have\n",
    "    df_sup = df_cleaned[(df_cleaned['Group'] == \"By Year\")]\n",
    "\n",
    "    # We are only looking at BRFSS data from 2021 and 2022, so we will filter this to match\n",
    "    df_sup = df_sup[(df_sup['Year'] == 2021) | (df_sup['Year'] == 2022)] \n",
    "\n",
    "    # Map conditions for consistency with cdc dataset\n",
    "    df_sup['Condition_new'] = df_sup['Condition'].map({\n",
    "        'Hypertensive diseases': 'Heart Disease', 'Ischemic heart disease': 'Heart Disease',\n",
    "        'Cardiac arrest': 'Heart Disease', 'Cardiac arrhythmia': 'Heart Disease',\n",
    "        'Heart failure': 'Heart Disease', 'Chronic lower respiratory diseases': 'Asthma',\n",
    "        'Renal failure': 'Kidney Disease', 'Diabetes': 'Diabetes', 'Obesity': 'Obesity'\n",
    "    })\n",
    "    df_sup = df_sup[df_sup['Condition_new'].notna()]\n",
    "\n",
    "    # Map age groups for consistency with cdc dataset\n",
    "    rlist = ['65-74', '75-84', '85+']\n",
    "    df_sup['Age Group'] = df_sup['Age Group'].mask(df_sup['Age Group'].isin(rlist), '65+')\n",
    "\n",
    "    # New York City is a separate count in this dataset but not in our other datasets, so we will add those numbers to New York State's count\n",
    "    df_sup['state_abbr'] = df_sup['state_abbr'].replace('NYC', 'NY')\n",
    "    df_sup['State'] = df_sup['State'].replace('NEW YORK CITY', 'NEW YORK')\n",
    "\n",
    "    # Drop unnecessary columns, reaggregate the new age group and rename columns where needed\n",
    "    df_sup = df_sup.drop(columns=['Start Date', 'End Date', 'Condition', 'Condition Group'])\n",
    "    df_sup = df_sup.groupby(['Year', 'Age Group', 'state_abbr', 'Condition_new']).agg({\"COVID-19 Deaths\": \"sum\"}).reset_index()\n",
    "    df_sup.rename(columns={'state_abbr': 'State', 'Condition_new': 'Condition'}, inplace=True)\n",
    "\n",
    "    df_sup2 = df_sup.pivot(index = ['Year', 'Age Group', 'State'], columns = 'Condition', values = 'COVID-19 Deaths').reset_index()\n",
    "    df_sup2 = df_sup2.rename(columns={'Asthma': 'Asthma_covdeath', 'Diabetes': 'Diabetes_covdeath', 'Heart Disease': 'Heart Disease_covdeath',\n",
    "                      'Kidney Disease': 'Kidney Disease_covdeath', 'Obesity': 'Obesity_covdeath'})\n",
    "\n",
    "    #Here we will focus on cleaning specifically for the Unsupervised portion of the project\n",
    "    df_unsup = df_cleaned.copy()\n",
    "\n",
    "    # Ensure 'start_date' and 'end_date' are in datetime format\n",
    "    df_unsup['Start Date'] = pd.to_datetime(df_unsup['Start Date'])\n",
    "    df_unsup['End Date'] = pd.to_datetime(df_unsup['End Date'])\n",
    "\n",
    "    # Calculate the time difference in days, months, and years\n",
    "    days_difference = (df_unsup['End Date'] - df_unsup['Start Date']).dt.days\n",
    "    # months_difference = days_difference / 30.44\n",
    "    years_difference = days_difference / 365.25  # Accounts for leap years\n",
    "\n",
    "    # Create new columns for daily, monthly, and yearly averages of covid_19_deaths\n",
    "    # df_unsup['daily_avg'] = df_unsup['COVID-19 Deaths'] / days_difference\n",
    "    # df_unsup['monthly_avg'] = df_unsup['COVID-19 Deaths'] / months_difference\n",
    "    df_unsup['yearly_avg'] = df_unsup['COVID-19 Deaths'] / years_difference\n",
    "\n",
    "    # # Drop unnecessary columns and reset the index\n",
    "    # df_unsup = df_unsup.drop(columns=['Start Date', 'End Date', 'Year', 'COVID-19 Deaths', 'Group'])\n",
    "    \n",
    "    df_unsup = df_unsup.groupby('state_abbr').agg({'yearly_avg': 'mean'}).reset_index()\n",
    "\n",
    "    return df_sup2, df_unsup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean/Parse Mortality Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mortality_dataset():\n",
    "    \"\"\"\n",
    "    Cleans and aggregates the cardiovascular disease mortality dataset.\n",
    "\n",
    "    Returns:\n",
    "        df_cleaned: A cleaned dataframe for use in the unsupervised portion of the project\n",
    "    \"\"\"\n",
    "\n",
    "    # Pass in imported mortality dataset\n",
    "    df = import_mortality()\n",
    "\n",
    "    # Impute at county level\n",
    "    df_mortality_county = df[df['GeographicLevel'] == 'County'].copy()\n",
    "\n",
    "    # Convert lat and lon coordinates into radians\n",
    "    for col in df_mortality_county[[\"Y_lat\", \"X_lon\"]]:\n",
    "        rad = np.deg2rad(df_mortality_county[col].values)\n",
    "        df_mortality_county[f'{col}_rad'] = rad\n",
    "\n",
    "    # Use Ball Tree to reduce search time for missing data. Ball tree only works on radian data\n",
    "    df_mortality_county_without_nan = df_mortality_county[df_mortality_county['Data_Value'].notna()].copy()\n",
    "    ball = BallTree(df_mortality_county_without_nan[['Y_lat_rad', 'X_lon_rad']].values, metric='haversine')\n",
    "\n",
    "    # Efficiently find four nearest neighbor counties and avg the data from them\n",
    "    def impute_from_neigbours(row):\n",
    "        if np.isnan(row['Data_Value']):\n",
    "            _, indices = ball.query([row[['Y_lat_rad', 'X_lon_rad']].values], k=4)\n",
    "            row['Data_Value'] = df_mortality_county_without_nan.iloc[indices[0]]['Data_Value'].mean()\n",
    "        return row\n",
    "    \n",
    "    # Impute at county level\n",
    "    df_mortality_county_imputed = df_mortality_county.apply(impute_from_neigbours, axis=1)\n",
    "\n",
    "    # Aggregate data for unsupervised portion of project\n",
    "    df_cleaned = df_mortality_county_imputed.groupby('LocationAbbr').agg({'Data_Value': 'mean'}).reset_index()\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge BRFSS surveys and clean/calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cdc_unsup():\n",
    "    \"\"\"\n",
    "    Cleans and aggregates the CDC BRFSS survey dataset for the unsupervised portion of the project.\n",
    "\n",
    "    Returns:\n",
    "        df_cleaned: A cleaned dataframe for use in the unsupervised portion of the project\n",
    "    \"\"\"\n",
    "    # Import the dataset\n",
    "    df = import_cdc_survey_2022()\n",
    "\n",
    "    # Map General Health\n",
    "    df['General Health'] = df['General Health'].map({\n",
    "        'Excellent': 5, 'Very good': 4, 'Good': 3, 'Fair': 2, 'Poor': 1\n",
    "    })\n",
    "\n",
    "    # Map Smoking \n",
    "    df['Smoking'] = df['Smoking'].map({\n",
    "        'never': 0,      # Non-smoker\n",
    "        'some_days': 1,  # Occasional smoker\n",
    "        'every_day': 2,  # Daily smoker\n",
    "    })\n",
    "\n",
    "    # Map True to 1 and False to 0 for 'Exercise in Past 30 Days'\n",
    "    df['Exercise in Past 30 Days'] = df['Exercise in Past 30 Days'].map({\n",
    "        True: 1,\n",
    "        False: 0\n",
    "    })\n",
    "\n",
    "    # Map categorical 'Years Since Last Checkup' values to numeric\n",
    "    df['Years Since Last Checkup'] = df['Years Since Last Checkup'].map({\n",
    "        'within_past_year': 1,\n",
    "        'within_past_two_years': 2,\n",
    "        'within_past_five_years': 3,\n",
    "        'five_or_more_years': 5\n",
    "    })\n",
    "\n",
    "    # Map categorical BMI values to numeric\n",
    "    df['BMI Category'] = df['BMI Category'].map({\n",
    "        'underweight': 0,\n",
    "        'normal_weight': 1,\n",
    "        'over_weight': 2,\n",
    "        'obese': 3\n",
    "    })\n",
    "\n",
    "    # Replace NaN values in 'Cigarettes per Day' and 'Drinks in Last 30 Days' with 0\n",
    "    # This is so we can get a average\n",
    "    df['Cigarettes per Day'] = df['Cigarettes per Day'].fillna(0)\n",
    "    df['Drinks in Last 30 Days'] = df['Drinks in Last 30 Days'].fillna(0)\n",
    "\n",
    "    # Aggregating df_cdc_survey\n",
    "    df_cleaned = df.groupby('State Abbr.').agg({\n",
    "        'General Health': 'mean', \n",
    "        'Exercise in Past 30 Days': 'mean', \n",
    "        'Smoking': 'mean', \n",
    "        'Shortness of Breath': 'sum', \n",
    "        'Hours of Sleeping': 'mean',\n",
    "        'BMI Category': 'mean',\n",
    "        'Years Since Last Checkup': 'mean',\n",
    "        'Cigarettes per Day': 'mean',\n",
    "        'Drinks in Last 30 Days': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cdc_sup():\n",
    "    \"\"\"\n",
    "    Cleans and aggregates the CDC BRFSS survey dataset for the supervised portion of the project. Also merges the 2021 and 2022 data.\n",
    "\n",
    "    Returns:\n",
    "        df_agg: A cleaned dataframe for use in the supervised portion of the project\n",
    "    \"\"\"\n",
    "\n",
    "    # Import data\n",
    "    df21 = import_cdc_survey_2021()\n",
    "    df22 = import_cdc_survey_2022()\n",
    "\n",
    "    # Confirm that each dataset only contains the year it's supposed to\n",
    "    df21 = df21[df21['Interview Year'] == 2021]\n",
    "    df22 = df22[df22['Interview Year'] == 2022]\n",
    "\n",
    "    # Filter out unnecessary columns; this was done upon import for the 2021 dataset\n",
    "    df22 = df22[['State Abbr.', 'Interview Year', 'Heart Disease', 'Asthma', 'Kidney Disease', 'Diabetes', 'Age Group', 'BMI Category']]\n",
    "\n",
    "    # Merge the two datasets\n",
    "    df = pd.concat([df21, df22])\n",
    "\n",
    "    # Get total count of responses per year, age group, and state so that we can create a percentage\n",
    "    temp = df.groupby(['Interview Year', 'Age Group', 'State Abbr.']).count()['Diabetes']\n",
    "    temp = temp.rename('Response Count')\n",
    "    dfmerge = pd.merge(temp, df, how='inner', on=['Interview Year', 'Age Group', 'State Abbr.'])\n",
    "\n",
    "    # Simplify BMI to classify obesity or none\n",
    "    dfmerge.loc[dfmerge['BMI Category'] == 'obese', 'Obesity'] = 1\n",
    "    dfmerge.loc[dfmerge['BMI Category'] != 'obese', 'Obesity'] = 0\n",
    "    dfmerge['Obesity'] = dfmerge['Obesity'].astype(int)\n",
    "\n",
    "    # Rename columns where needed\n",
    "    dfmerge = dfmerge.rename(columns={'State Abbr.': 'State', 'Interview Year': 'Year'})\n",
    "\n",
    "    # Replace all boolean values with 0/1 values to make summarizing easier\n",
    "    dfmerge = dfmerge.replace({True: 1, False: 0})\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    dfmerge = dfmerge.drop(columns=['BMI Category'])\n",
    "\n",
    "    # Map age groups for consistency with COVID dataset\n",
    "    dfmerge['Age Group'] = dfmerge['Age Group'].map({\n",
    "        'between_18_and_24': '0-24', 'between_25_and_34': '25-34', 'between_35_and_44': '35-44',\n",
    "        'between_45_and_54': '45-54', 'between_55_and_64': '55-64', 'older_than_65': '65+'\n",
    "    })\n",
    "\n",
    "    # Aggregate data by state, interview year, and age group\n",
    "    df_agg = dfmerge.groupby(['State', 'Year', 'Age Group']).agg({\"Heart Disease\": \"sum\", \"Asthma\": \"sum\", \"Kidney Disease\": \"sum\",\n",
    "                                                                  \"Diabetes\": \"sum\", \"Obesity\": \"sum\", \"Response Count\": \"mean\"}).reset_index()\n",
    "    \n",
    "    # Convert counts to percentages so that we can generalize to the population\n",
    "    df_agg['Heart Disease'] = df_agg['Heart Disease'] / df_agg['Response Count']\n",
    "    df_agg['Asthma'] = df_agg['Asthma'] / df_agg['Response Count']\n",
    "    df_agg['Kidney Disease'] = df_agg['Kidney Disease'] / df_agg['Response Count']\n",
    "    df_agg['Diabetes'] = df_agg['Diabetes'] / df_agg['Response Count']\n",
    "    df_agg['Obesity'] = df_agg['Obesity'] / df_agg['Response Count']\n",
    "\n",
    "    # Drop unnecessary column\n",
    "    df_agg = df_agg.drop(columns=['Response Count'])\n",
    "\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Resident Population dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_census():\n",
    "    \"\"\"\n",
    "    Cleans and aggregates the US Census dataset for the supervised portion of the project.\n",
    "\n",
    "    Returns:\n",
    "        df_agg: A cleaned dataframe for use in the supervised portion of the project\n",
    "    \"\"\"\n",
    "\n",
    "    # Import the dataset\n",
    "    df = import_pop_dataset()\n",
    "\n",
    "    # Filter dataset to alleviate duplicate counting\n",
    "    df = df[(df['SEX'] == 0) & (df['ORIGIN'] == 0)]\n",
    "\n",
    "    # Dictionary to map state names to abbreviations\n",
    "    state_name_to_abbr = {\n",
    "        'ALABAMA': 'AL', 'ALASKA': 'AK', 'ARIZONA': 'AZ', 'ARKANSAS': 'AR', \n",
    "        'CALIFORNIA': 'CA', 'COLORADO': 'CO', 'CONNECTICUT': 'CT', 'DELAWARE': 'DE', \n",
    "        'DISTRICT OF COLUMBIA': 'DC', 'FLORIDA': 'FL', 'GEORGIA': 'GA', 'HAWAII': 'HI', \n",
    "        'IDAHO': 'ID', 'ILLINOIS': 'IL', 'INDIANA': 'IN', 'IOWA': 'IA', 'KANSAS': 'KS', \n",
    "        'KENTUCKY': 'KY', 'LOUISIANA': 'LA', 'MAINE': 'ME', 'MARYLAND': 'MD', \n",
    "        'MASSACHUSETTS': 'MA', 'MICHIGAN': 'MI', 'MINNESOTA': 'MN', 'MISSISSIPPI': 'MS', \n",
    "        'MISSOURI': 'MO', 'MONTANA': 'MT', 'NEBRASKA': 'NE', 'NEVADA': 'NV', \n",
    "        'NEW HAMPSHIRE': 'NH', 'NEW JERSEY': 'NJ', 'NEW MEXICO': 'NM', 'NEW YORK': 'NY', \n",
    "        'NORTH CAROLINA': 'NC', 'NORTH DAKOTA': 'ND', 'OHIO': 'OH', \n",
    "        'OKLAHOMA': 'OK', 'OREGON': 'OR', 'PENNSYLVANIA': 'PA', 'RHODE ISLAND': 'RI', \n",
    "        'SOUTH CAROLINA': 'SC', 'SOUTH DAKOTA': 'SD', 'TENNESSEE': 'TN', 'TEXAS': 'TX', \n",
    "        'UTAH': 'UT', 'VERMONT': 'VT', 'VIRGINIA': 'VA', 'WASHINGTON': 'WA', \n",
    "        'WEST VIRGINIA': 'WV', 'WISCONSIN': 'WI', 'WYOMING': 'WY', 'PUERTO RICO': 'PR'\n",
    "    }\n",
    "\n",
    "    # Convert state names to abbreviations for consistency\n",
    "    df['NAME'] = df['NAME'].str.upper()\n",
    "    df['State'] = df['NAME'].map(state_name_to_abbr)\n",
    "\n",
    "    # Check that there are no blank values in the age column\n",
    "    df['AGE'] = df['AGE'].astype(int)\n",
    "    df = df[df['AGE'].notna()]\n",
    "\n",
    "    # Map the ages to the same age range we have in the other datasets\n",
    "    criteria = [df['AGE'].between(0,24), df['AGE'].between(25,34), df['AGE'].between(35,44), df['AGE'].between(45,54), df['AGE'].between(55,64), df['AGE'].between(65,1000)]\n",
    "    values = ['0-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "    df['Age Group'] = np.select(criteria, values, \"Check\")\n",
    "\n",
    "    # Get updated counts for age ranges\n",
    "    df_agg = df.groupby(['Age Group', 'State']).agg({'POPESTIMATE2021': 'sum', 'POPESTIMATE2022': 'sum'}).reset_index()\n",
    "\n",
    "    # Rename columns for the pivot table\n",
    "    df_agg = df_agg.rename(columns={'POPESTIMATE2021': 2021, 'POPESTIMATE2022': 2022})\n",
    "\n",
    "    # Unpivot so that we have a year column\n",
    "    df_melt = pd.melt(df_agg, id_vars = ['Age Group', 'State'], value_vars = [2021, 2022], var_name = \"Year\", value_name = \"Population\")\n",
    "\n",
    "    # Ensure correct datatype\n",
    "    df_melt['Population'] = df_melt['Population'].astype(int)\n",
    "    \n",
    "    return df_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge datasets for Supervised Learning project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sup_df():\n",
    "    \"\"\"\n",
    "    Merges the population, both CDC, and COVID datasets and performs feature engineering to extract useful features for the supervised learning portion of the project.\n",
    "\n",
    "    Returns:\n",
    "        df: A cleaned, merged dataframe for use in the supervised learning portion of the project\n",
    "    \"\"\"\n",
    "\n",
    "    # Import all necessary datasets\n",
    "    pop = clean_census()\n",
    "    covid, _ = clean_covid_dataset()\n",
    "    cdc = clean_cdc_sup()\n",
    "\n",
    "    # Merge datasets\n",
    "    df_cov_cdc = pd.merge(cdc, covid, how='inner', on=['Year', 'Age Group', 'State']).reset_index(drop=True)\n",
    "    df_merged = pd.merge(df_cov_cdc, pop, how='inner', on=['Year', 'Age Group', 'State']).reset_index(drop=True)\n",
    "\n",
    "    # Final feature engineering calculations\n",
    "    df_merged['All Conditions_covdeath'] = df_merged[['Obesity_covdeath', 'Kidney Disease_covdeath', 'Asthma_covdeath', 'Diabetes_covdeath', 'Heart Disease_covdeath']].sum(axis=1)\n",
    "    df_merged['Rate of COVID Deaths Due to Conditions'] = df_merged['All Conditions_covdeath'] / df_merged['Population']\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    df = df_merged[['State', 'Year', 'Age Group', 'Heart Disease', 'Asthma', 'Kidney Disease', 'Diabetes', 'Obesity', 'Population', 'Rate of COVID Deaths Due to Conditions']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge datasets for Unsupervised Learning project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unsup_df():\n",
    "    \"\"\"\n",
    "    Merges the mortality, CDC, and COVID datasets to create a dataset for unsupervised analysis.\n",
    "\n",
    "    Returns:\n",
    "        df: A cleaned, merged dataframe for use in the unsupervised\n",
    "    \"\"\"\n",
    "\n",
    "    # Get datasets to merge\n",
    "    _, covid = clean_covid_dataset()\n",
    "    mortality = clean_mortality_dataset()\n",
    "    cdc = clean_cdc_unsup()\n",
    "\n",
    "    # Merge cdc with mortality\n",
    "    df = cdc.merge(mortality, left_on = 'State Abbr.', right_on = 'LocationAbbr', how = 'inner')\n",
    "\n",
    "    # Merge the result with covid\n",
    "    df = df.merge(covid, left_on = 'State Abbr.', right_on = 'state_abbr', how = 'inner')\n",
    "\n",
    "    # Drop duplicate columns for state\n",
    "    df.drop(columns = ['LocationAbbr', 'state_abbr'], inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
